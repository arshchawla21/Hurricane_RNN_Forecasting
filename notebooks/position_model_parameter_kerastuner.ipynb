{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7b780-01c3-448d-a39f-19e578cf5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9dac2ce-d66f-4ea9-aee9-89deb3ee7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d43b7-1718-4ef3-b262-c6679578d28c",
   "metadata": {},
   "source": [
    "## Preproccessing Hurricane Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ee684e-a85b-4ba0-b3bf-2dd6829df479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Cyclone Data\n",
    "df = pd.read_csv(\"../raw-data/hurricaneData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f841d5-019c-4415-ae42-894e2d66c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all attributes, expect Longitude, Latitude, Time and SID\n",
    "simple_df = df.drop(['SEASON','NUMBER','BASIN','SUBBASIN','NAME','NATURE','WMO_WIND','WMO_PRES','WMO_AGENCY','TRACK_TYPE','DIST2LAND','LANDFALL','IFLAG'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f3042a-1499-4f50-8397-21018e96fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all data points prior to year=1900\n",
    "simple_df = simple_df.iloc[9461:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7970ddcb-5977-472e-8a44-f7cfc8384102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ISO_TIME to datetime\n",
    "simple_df['ISO_TIME'] = pd.to_datetime(simple_df['ISO_TIME'], format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c12be2d-e102-4e66-9c86-d5249cd2fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all data points which are not in 3 hour increments \n",
    "simple_df = simple_df[simple_df['ISO_TIME'].dt.hour % 3 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0829202c-5c3f-4032-87f5-e6e1222c9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert longitudes and latitudes to x, y, z coordinates\n",
    "def FeatureColumnsXYZ(dframe):\n",
    "    dframe['x'] = np.cos(np.radians(dframe.LAT)) * np.cos(np.radians(dframe.LON))\n",
    "    dframe['y'] = np.cos(np.radians(dframe.LAT)) * np.sin(np.radians(dframe.LON))\n",
    "    dframe['z'] = np.sin(np.radians(dframe.LAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61eb6df-8465-4b8d-ae24-f1eac44f0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureColumnsXYZ(simple_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270b8b0-3c78-41b7-a4bf-cd77a796dc07",
   "metadata": {},
   "source": [
    "We must now remove all hurricanes in the dataset with too few datapoints (<15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae45a25-6873-4f4d-a412-7a8dd8d02c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SID_values = []\n",
    "for value in simple_df['SID']:\n",
    "    if value not in SID_values:\n",
    "        SID_values.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034e3170-7f5a-4ace-8337-b2ac2ffd4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = simple_df.groupby('SID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "359e9c80-4458-4716-9af4-56ec7f2991aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all hurricanes with less than 15 data points approx ~200\n",
    "SID_to_drop = []\n",
    "for value in SID_values:\n",
    "    if len(grouped.groups[value]) < 15:\n",
    "        if value not in SID_to_drop:\n",
    "            SID_to_drop.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5628460e-7401-45a9-b0b9-8f90f3f9d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_by_sid(df, sid_list):\n",
    "    # Drop rows where the SID is in the sid_list\n",
    "    df_filtered = df[~df['SID'].isin(sid_list)]\n",
    "    \n",
    "    return df_filtered\n",
    "simple_df = drop_rows_by_sid(simple_df,SID_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4298bc3-8186-487b-9fc1-ffcc82b376af",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = simple_df.groupby('SID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2787356-6a51-4f3c-a81f-29d011ce6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countSID = []\n",
    "for value in simple_df['SID']:\n",
    "    if value not in countSID:\n",
    "        countSID.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2619cafd-cfb6-436c-acc2-d32c4b12be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: 3911\n",
      "new: 3649\n"
     ]
    }
   ],
   "source": [
    "# Confirm number of removed hurricanes\n",
    "print(\"original: \" + str(len(SID_values)))\n",
    "print(\"new: \" + str(len(countSID))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9775ff-9c37-41e2-b8ff-4186059c11e3",
   "metadata": {},
   "source": [
    "## Building and Fine Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09ce5fc5-26f1-4b7b-b4e6-8904196f5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, window_size):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    grouped = df.groupby('SID')\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        for i in range(len(group) - window_size):\n",
    "            seq = group[['x', 'y', 'z']].iloc[i:i+window_size].values\n",
    "            target = group[['x', 'y', 'z']].iloc[i+window_size].values\n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "470af7f9-7734-4eeb-aaeb-39ed63c07753",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 8 # 24 hours\n",
    "X, y = create_sequences(simple_df, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1d1b15e-465c-48c8-b32d-2e803da96079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and evaluation\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af46722f-a2fb-4998-b70a-e5b59c098006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155897, 8, 3)\n",
      "(155897, 3)\n",
      "(38975, 8, 3)\n",
      "(38975, 3)\n"
     ]
    }
   ],
   "source": [
    "# Understand data shape\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_eval.shape)\n",
    "print(y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c45990d-7dc1-48e6-9ccb-186984b87844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(8, 3)))\n",
    "    model.add(\n",
    "        layers.LSTM(\n",
    "            # Tune number of units.\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "            # Tune the activation function to use.\n",
    "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "        )\n",
    "    )\n",
    "    # Tune whether to use dropout.\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6334229d-d29d-4ff9-b85f-99ea313ee7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "597d3134-1f9f-4efa-a248-9cb473416724",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"cur_dir\",\n",
    "    project_name=\"hurricane_RNN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78f713fe-719b-4e32-970b-19c736a11ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33f25dc8-b897-42aa-8f0d-b782d4bda6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 09m 27s]\n",
      "val_accuracy: 0.8180115222930908\n",
      "\n",
      "Best val_accuracy So Far: 0.8180115222930908\n",
      "Total elapsed time: 00h 27m 19s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=5, validation_data=(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5014cc9-321b-4dc2-9e26-9263469c76a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
